{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 208)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "train_set = pd.read_csv('train.csv')\n",
    "test_set = pd.read_csv('test.csv')\n",
    "\n",
    "train_set.drop(['ID_code'], axis = 1, inplace = True)\n",
    "train_set.head()\n",
    "\n",
    "idx = train_set.columns.values[1:]\n",
    "for df in [test_set, train_set]:\n",
    "    df['sum'] = df[idx].sum(axis=1)  \n",
    "    df['min'] = df[idx].min(axis=1)\n",
    "    df['max'] = df[idx].max(axis=1)\n",
    "    df['mean'] = df[idx].mean(axis=1)\n",
    "    df['std'] = df[idx].std(axis=1)\n",
    "    df['skew'] = df[idx].skew(axis=1)\n",
    "    df['kurt'] = df[idx].kurtosis(axis=1)\n",
    "    df['med'] = df[idx].median(axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = np.array(train_set)[:, 0]\n",
    "X = np.array(train_set)[:, 1:]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaller = StandardScaler()\n",
    "X = scaller.fit_transform(X)\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "q_scaller = QuantileTransformer()\n",
    "X = q_scaller.fit_transform(X)\n",
    "\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 9,\n",
    "         'min_data_in_leaf': 42,\n",
    "         'objective': 'binary',\n",
    "         'max_depth': 16,\n",
    "         'learning_rate': 0.0123,\n",
    "         'boosting': 'gbdt',\n",
    "         'bagging_freq': 5,\n",
    "         'bagging_fraction': 0.8,\n",
    "         'feature_fraction': 0.8201,\n",
    "         'bagging_seed': 11,\n",
    "         'reg_alpha': 1.728910519108444,\n",
    "         'reg_lambda': 4.9847051755586085,\n",
    "         'random_state': 42,\n",
    "         'metric': 'auc',\n",
    "         'verbosity': -1,\n",
    "         'subsample': 0.81,\n",
    "         'min_gain_to_split': 0.01077313523861969,\n",
    "         'min_child_weight': 19.428902804238373,\n",
    "         'num_threads': 4}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = np.array(test_set)[:, 1:]\n",
    "test_X = test_X.astype(float)\n",
    "test_X = scaller.transform(test_X)\n",
    "test_X = q_scaller.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds.get_n_splits(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's auc: 0.88941\tvalid_1's auc: 0.86355\n",
      "[2000]\ttraining's auc: 0.913579\tvalid_1's auc: 0.882586\n",
      "[3000]\ttraining's auc: 0.924802\tvalid_1's auc: 0.890298\n",
      "[4000]\ttraining's auc: 0.931667\tvalid_1's auc: 0.894451\n",
      "[5000]\ttraining's auc: 0.936712\tvalid_1's auc: 0.896671\n",
      "[6000]\ttraining's auc: 0.941098\tvalid_1's auc: 0.897912\n",
      "[7000]\ttraining's auc: 0.945359\tvalid_1's auc: 0.898304\n",
      "[8000]\ttraining's auc: 0.949333\tvalid_1's auc: 0.8986\n",
      "Early stopping, best iteration is:\n",
      "[7945]\ttraining's auc: 0.949136\tvalid_1's auc: 0.898662\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's auc: 0.889969\tvalid_1's auc: 0.861768\n",
      "[2000]\ttraining's auc: 0.91458\tvalid_1's auc: 0.8805\n",
      "[3000]\ttraining's auc: 0.925959\tvalid_1's auc: 0.88812\n",
      "[4000]\ttraining's auc: 0.932749\tvalid_1's auc: 0.89161\n",
      "[5000]\ttraining's auc: 0.937657\tvalid_1's auc: 0.89323\n",
      "[6000]\ttraining's auc: 0.942025\tvalid_1's auc: 0.894008\n",
      "[7000]\ttraining's auc: 0.946264\tvalid_1's auc: 0.894311\n",
      "Early stopping, best iteration is:\n",
      "[7041]\ttraining's auc: 0.946436\tvalid_1's auc: 0.894324\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's auc: 0.889764\tvalid_1's auc: 0.863851\n",
      "[2000]\ttraining's auc: 0.913759\tvalid_1's auc: 0.882843\n",
      "[3000]\ttraining's auc: 0.92504\tvalid_1's auc: 0.890737\n",
      "[4000]\ttraining's auc: 0.931854\tvalid_1's auc: 0.894718\n",
      "[5000]\ttraining's auc: 0.936947\tvalid_1's auc: 0.896578\n",
      "[6000]\ttraining's auc: 0.941428\tvalid_1's auc: 0.897361\n",
      "[7000]\ttraining's auc: 0.945712\tvalid_1's auc: 0.897727\n",
      "Early stopping, best iteration is:\n",
      "[6925]\ttraining's auc: 0.945398\tvalid_1's auc: 0.897792\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's auc: 0.888723\tvalid_1's auc: 0.869152\n",
      "[2000]\ttraining's auc: 0.912816\tvalid_1's auc: 0.887312\n",
      "[3000]\ttraining's auc: 0.924498\tvalid_1's auc: 0.894603\n",
      "[4000]\ttraining's auc: 0.931382\tvalid_1's auc: 0.897737\n",
      "[5000]\ttraining's auc: 0.936264\tvalid_1's auc: 0.899495\n",
      "[6000]\ttraining's auc: 0.940692\tvalid_1's auc: 0.900209\n",
      "Early stopping, best iteration is:\n",
      "[5905]\ttraining's auc: 0.940252\tvalid_1's auc: 0.900252\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's auc: 0.888511\tvalid_1's auc: 0.867778\n",
      "[2000]\ttraining's auc: 0.913355\tvalid_1's auc: 0.886946\n",
      "[3000]\ttraining's auc: 0.92499\tvalid_1's auc: 0.89406\n",
      "[4000]\ttraining's auc: 0.931952\tvalid_1's auc: 0.897214\n",
      "[5000]\ttraining's auc: 0.936906\tvalid_1's auc: 0.898615\n",
      "[6000]\ttraining's auc: 0.941367\tvalid_1's auc: 0.899408\n",
      "Early stopping, best iteration is:\n",
      "[6562]\ttraining's auc: 0.943806\tvalid_1's auc: 0.899563\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.zeros(len(test_X))\n",
    "for train_index, test_index in folds.split(X, y):\n",
    "    train_data = lgb.Dataset(X[train_index,:], label = y[train_index])\n",
    "    val_data = lgb.Dataset(X[test_index,:], label = y[test_index])\n",
    "    model = lgb.train(params, train_data, num_boost_round=15000,\n",
    "                  valid_sets=[train_data, val_data],\n",
    "                  verbose_eval = 1000, early_stopping_rounds = 200)\n",
    "    y_pred += model.predict(test_X,\n",
    "                           num_iteration=model.best_iteration)\n",
    "y_pred /= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_data = lgb.Dataset(X_train, label = y_train)\n",
    "# val_data = lgb.Dataset(X_test, label = y_test)\n",
    "# model = lgb.train(param, train_data, num_boost_round=15000,\n",
    "#                   valid_sets=[train_data, val_data],\n",
    "#                   verbose_eval = 1000, early_stopping_rounds = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# full_data = lgb.Dataset(X, label = y)\n",
    "# model_2 = lgb.cv(param, full_data, num_boost_round=15000,\n",
    "#                  nfold = 10, verbose_eval = 1000, \n",
    "#                  early_stopping_rounds = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# cm = confusion_matrix(y, (model.predict(X) > 0.5))\n",
    "# print(cm)\n",
    "# print((cm[0,1]+ cm[1,1])/np.sum(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hakunamatata/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: set_axis currently defaults to operating inplace.\n",
      "This will change in a future version of pandas, use inplace=True to avoid this warning.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "anwser = pd.concat([test_set['ID_code'],\n",
    "                     pd.DataFrame(y_pred)], axis=1)\n",
    "\n",
    "\n",
    "anwser.set_axis(['ID_code', 'target'], axis = 1)\n",
    "anwser.head()\n",
    "\n",
    "anwser.to_csv('anwser.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('lgbmodel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
